{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IWIV6p92AlXU",
        "f5o0E1qNonUE",
        "7YNUtE8LXQ1E",
        "zcJTVIlbAZ86"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lbhagavan/stanford_LLM_Leela/blob/homework/Carlos_LLM_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install"
      ],
      "metadata": {
        "id": "6NMpOMxVAwHc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94n44LlK-Ph9",
        "outputId": "657cfa87-f757-498a-dfb6-be4f15c6e532",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.42.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.35)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.104)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.42.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.11.1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.3)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post3)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (1.42.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.1->llama-index) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (3.3)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (9.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.16.0)\n",
            "Requirement already satisfied: llama-cloud>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.0.15)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.2.0->llama-index) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (0.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.1->llama-index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.4/259.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.7/427.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# OpenAI - Llama Index - Langchain\n",
        "!pip install openai\n",
        "!pip install sentence-transformers\n",
        "!pip install langchain pypdf langchain-openai\n",
        "!pip install llama-index --upgrade\n",
        "\n",
        "# SubQuery\n",
        "!pip install nest-asyncio\n",
        "\n",
        "# CrewAI - DuckDuckGo - GoogleGenAI\n",
        "%pip install --q crewai\n",
        "%pip install --q -U duckduckgo-search\n",
        "%pip install --q langchain_google_genai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get Data"
      ],
      "metadata": {
        "id": "IWIV6p92AlXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://static.www.nfl.com/image/upload/league/apps/league-site/media-guides/2022/2022_NFL_Record_and_Fact_Book.pdf?cid=nfl-history\n",
        "!wget https://operations.nfl.com/media/hfjn4oid/2024-record-fact-book-incl-supplemental.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GjfaIS1-k72",
        "outputId": "5c69cdb3-64be-4adb-afb0-34b5481854f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-27 00:53:10--  https://operations.nfl.com/media/hfjn4oid/2024-record-fact-book-incl-supplemental.pdf\n",
            "Resolving operations.nfl.com (operations.nfl.com)... 151.101.1.153, 151.101.65.153, 151.101.129.153, ...\n",
            "Connecting to operations.nfl.com (operations.nfl.com)|151.101.1.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27181782 (26M) [application/pdf]\n",
            "Saving to: ‘2024-record-fact-book-incl-supplemental.pdf’\n",
            "\n",
            "2024-record-fact-bo 100%[===================>]  25.92M   166MB/s    in 0.2s    \n",
            "\n",
            "2024-08-27 00:53:12 (166 MB/s) - ‘2024-record-fact-book-incl-supplemental.pdf’ saved [27181782/27181782]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & Config"
      ],
      "metadata": {
        "id": "1eQbZGFFA8W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "open_ai_key = userdata.get('api_key')\n",
        "client = OpenAI(api_key=open_ai_key)\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
        "\n",
        "# Import necessary classes from the llama_index package\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, SummaryIndex\n",
        "from llama_index.core import Settings\n"
      ],
      "metadata": {
        "id": "Pq5E_qg_-o5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read Data"
      ],
      "metadata": {
        "id": "f5o0E1qNonUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the data\n",
        "documents = SimpleDirectoryReader(\"./\").load_data(\"2024-record-fact-book-incl-supplemental.pdf\")\n",
        "\n",
        "\n",
        "# Read documents from the specified directory and load a specific document, \"report.pdf\".\n",
        "# documents = SimpleDirectoryReader(\"./final_project\").load_data(\"*.pdf\")\n",
        "# reader1 = SimpleDirectoryReader(\"./final_project/bets\")\n",
        "# reader2 = SimpleDirectoryReader(\"./final_project/docs\")\n",
        "# reader3 = SimpleDirectoryReader(\"./final_project/teams\")\n",
        "\n",
        "# Load data from each directory\n",
        "# bets = reader1.load_data(\"*.pdf\")\n",
        "# docs = reader2.load_data(\"*.pdf\")\n",
        "# teams = reader3.load_data(\"*.pdf\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPZGpb5OovhE",
        "outputId": "d4fbcdef-a1f5-44da-899a-b470be9057cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading files: 100%|██████████| 1/1 [02:08<00:00, 128.18s/file]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RAG & Chat"
      ],
      "metadata": {
        "id": "7YNUtE8LXQ1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the data\n",
        "documents = SimpleDirectoryReader(\"./\").load_data(\"2024-record-fact-book-incl-supplemental.pdf\")\n",
        "# bets + docs + teams\n",
        "\n",
        "# Create a VectorStoreIndex object from the documents. This will involve processing the documents\n",
        "# and creating a vector representation for each of them, suitable for semantic searching.\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "\n",
        "# Convert the VectorStoreIndex object into a query engine. This query engine can be used to\n",
        "# perform semantic searches on the index, matching natural language queries to the most relevant\n",
        "# documents in the index.\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Use the query engine to search for documents that are relevant to the query\n",
        "# from the indexed documents based on the semantic understanding of the query.\n",
        "response = query_engine.query(\"Is 49ers a team in NFL?\")\n",
        "\n",
        "# chat_engine to test chat functionality\n",
        "chat_engine = index.as_chat_engine(chat_mode=\"openai\", tool_choice=\"query_engine_tool\", verbose=False)\n",
        "\n",
        "# initialize settings (set chunk size)\n",
        "Settings.chunk_size = 1024\n",
        "nodes = Settings.node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# Create a VectorStoreIndex object from the documents. This will involve processing the documents\n",
        "# and creating a vector representation for each of them, suitable for semantic searching.\n",
        "summary_index = SummaryIndex(nodes)\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "650Tbb2S-t5v",
        "outputId": "817e04a5-ab2f-47ab-9749-02cf960e8b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading files: 100%|██████████| 1/1 [02:12<00:00, 132.86s/file]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests RAG"
      ],
      "metadata": {
        "id": "zcJTVIlbAZ86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the response obtained from the query. This will display the result of the semantic search,\n",
        "# showing the information or documents that best match the query about the 2024 outlook.\n",
        "response = query_engine.query(\"Does the 49ers the best team in NFC West?\")\n",
        "print(\"RAG => Does the 49ers the best team in NFC West?\")\n",
        "print(response)\n",
        "print(\"==========\")\n",
        "\n",
        "response = query_engine.query(\"Which is the team that the 49ers beat more in NFL?\")\n",
        "print(\"RAG => Which is the team that the 49ers beat more in the NFL?\")\n",
        "print(response)\n",
        "print(\"==========\")\n",
        "\n",
        "response = query_engine.query(\"Is the 49ers favorite to win NFC this season?\")\n",
        "print(\"RAG => Which is the best NFL team based on the current data?\")\n",
        "print(response)\n",
        "print(\"==========\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nzb_cY6AeXu",
        "outputId": "e1350d28-e10b-44bf-9feb-7ed17047915a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG => Does the 49ers the best team in NFC West?\n",
            "The 49ers are one of the teams in the NFC West, but based on the context provided, it does not explicitly state whether they are the best team in the NFC West.\n",
            "==========\n",
            "RAG => Which is the team that the 49ers beat more in the NFL?\n",
            "The team that the 49ers beat more in the NFL is the Washington Redskins.\n",
            "==========\n",
            "RAG => Which is the best NFL team based on the current data?\n",
            "The context does not provide any information about the current season or the favorites to win the NFC.\n",
            "==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests Chat"
      ],
      "metadata": {
        "id": "biahK-00XXfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the response obtained from the chat.\n",
        "response = chat_engine.chat(\n",
        "    \"Does the 49ers the best team in NFC West?\"\n",
        ")\n",
        "print(\"CHAT => Does the 49ers the best team in NFC West?\")\n",
        "print(response)\n",
        "print(\"==========\")\n",
        "\n",
        "response = chat_engine.chat(\"Is the 49ers favorite to win NFC this season?\")\n",
        "print(\"CHAT => Is the 49ers favorite to win NFC this season?\")\n",
        "print(response)\n",
        "print(\"==========\")\n",
        "\n",
        "response = chat_engine.chat(\"Which is the team that the 49ers beat more in NFL?\")\n",
        "print(\"CHAT => Which is the team that the 49ers beat more in NFL?\")\n",
        "print(response)\n",
        "print(\"==========\")\n",
        "\n",
        "response = chat_engine.chat(\n",
        "    \"Which is the best NFL team based on the current data?\")\n",
        "print(\"CHAT => Which is the best NFL team based on the current data?\")\n",
        "print(response)\n",
        "print(\"==========\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWtAPF9jXZhF",
        "outputId": "ccb9834e-e0c4-446b-941a-4bf6387d3f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAT => Does the 49ers the best team in NFC West?\n",
            "Based on the information available, it is not explicitly stated whether the 49ers are the best team in the NFC West.\n",
            "==========\n",
            "CHAT => Is the 49ers favorite to win NFC this season?\n",
            "The 49ers are not the favorite to win the NFC this season.\n",
            "==========\n",
            "CHAT => Which is the team that the 49ers beat more in NFL?\n",
            "The 49ers have beaten the Rams the most in the NFL.\n",
            "==========\n",
            "CHAT => Which is the best NFL team based on the current data?\n",
            "Based on the current data provided, the best NFL team would be the Denver Broncos as they won the Super Bowl XXXII against the Green Bay Packers with a score of 31-24.\n",
            "==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sub Question Query Engine"
      ],
      "metadata": {
        "id": "gbicNAyvYPsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary classes and modules from llama_index.core and llama_index.core.tools\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "from llama_index.core import Settings\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Build a VectorStoreIndex from the loaded documents\n",
        "# This index will allow efficient querying of the document content\n",
        "vector_query_engine = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    use_async=True,  # Enable asynchronous processing for faster performance\n",
        ").as_query_engine()  # Convert the index to a query engine\n",
        "\n",
        "# Define a list of query engine tools, each with its own metadata\n",
        "# This setup is necessary for the SubQuestionQueryEngine\n",
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=vector_query_engine,  # Use the vector_query_engine built above\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"documents\",  # Name of the tool\n",
        "            description=\"Report\",  # Description of the tool\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Create an instance of SubQuestionQueryEngine using the default settings\n",
        "# This query engine can handle sub-questions and use the provided tools for querying\n",
        "query_engine = SubQuestionQueryEngine.from_defaults(\n",
        "    query_engine_tools=query_engine_tools,  # Provide the list of query engine tools\n",
        "    use_async=True,  # Enable asynchronous processing\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDZ74btrYThb",
        "outputId": "ec42eb35-13ed-4355-aab4-94ccc5f99641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/main.py:193: RuntimeWarning: coroutine 'run_async_tasks.<locals>._gather' was never awaited\n",
            "  self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/main.py:193: RuntimeWarning: coroutine 'SubQuestionQueryEngine._aquery_subq' was never awaited\n",
            "  self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/main.py:193: RuntimeWarning: coroutine 'VectorStoreIndex._async_add_nodes_to_index' was never awaited\n",
            "  self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests Sub Question Query"
      ],
      "metadata": {
        "id": "JD9PlV5xYYJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"Does the 49ers the best team in NFC West?\"\n",
        ")\n",
        "print(\"SUBQUERY => Does the 49ers the best team in NFC West?\")\n",
        "print(response.response)\n",
        "print(\"==========\")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"Which is the team that the 49ers beat more in NFL?\"\n",
        ")\n",
        "print(\"SUBQUERY => Which is the team that the 49ers beat more in NFL?\")\n",
        "print(response.response)\n",
        "print(\"==========\")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"Which is the best NFL team based on the current data?\"\n",
        ")\n",
        "print(\"SUBQUERY => Which is the best NFL team based on the current data?\")\n",
        "print(response.response)\n",
        "print(\"==========\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8iw55spYZeN",
        "outputId": "dc886970-3f0a-420e-9076-a7d2203e92a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 1 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[documents] Q: What is the current standing of the 49ers in the NFC West?\n",
            "\u001b[0m\u001b[1;3;38;2;237;90;200m[documents] A: The San Francisco 49ers currently have a standing of 114 wins and 96 losses in the NFC West.\n",
            "\u001b[0mSUBQUERY => Does the 49ers the best team in NFC West?\n",
            "The San Francisco 49ers may not necessarily be the best team in the NFC West based on their current standing of 114 wins and 96 losses in the division.\n",
            "==========\n",
            "Generated 1 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[documents] Q: List all the teams that the 49ers have beaten in NFL\n",
            "\u001b[0m\u001b[1;3;38;2;237;90;200m[documents] A: The teams that the 49ers have beaten in the NFL based on the provided context are the Bears, Rams, and Steelers.\n",
            "\u001b[0mSUBQUERY => Which is the team that the 49ers beat more in NFL?\n",
            "The team that the 49ers have beaten more in the NFL based on the provided context is the Rams.\n",
            "==========\n",
            "Generated 2 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[documents] Q: What is the current ranking of NFL teams?\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[documents] Q: What are the recent performance statistics of NFL teams?\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[documents] A: The recent performance statistics of NFL teams show that the NFC Total rushing yards for the season were 7374, with a total of 31302 rushing yards gained. The NFC teams had an average of 460.9 rushing yards per game and an average of 1956.4 rushing yards per season. The average yards per rush for NFC teams was 4.2, with a total of 235 rushing touchdowns scored. The NFC teams had a longest rushing play of 75 yards.\n",
            "\u001b[0m\u001b[1;3;38;2;237;90;200m[documents] A: The current ranking of NFL teams is as follows:\n",
            "\n",
            "AFC:\n",
            "1. Kansas City\n",
            "2. Pittsburgh\n",
            "3. New England\n",
            "4. Denver\n",
            "5. Jacksonville\n",
            "6. Miami\n",
            "\n",
            "NFC:\n",
            "1. San Francisco\n",
            "2. Green Bay\n",
            "3. N.Y. Giants\n",
            "4. Tampa Bay\n",
            "5. Detroit\n",
            "6. Minnesota\n",
            "\u001b[0mSUBQUERY => Which is the best NFL team based on the current data?\n",
            "San Francisco is the best NFL team based on the current data.\n",
            "==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Agents"
      ],
      "metadata": {
        "id": "qgt9pL4aYybD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_openai import OpenAI\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "\n",
        "llm = OpenAI(temperature=0.1, openai_api_key=userdata.get('api_key'))\n",
        "\n",
        "def getAgentsTasks(question_to_answer, verbose):\n",
        "  # Define your agents with roles and goals\n",
        "  researcher = Agent(\n",
        "    role='Senior Research Analyst',\n",
        "    goal=f'Conduct comprehensive research to answer the question {question_to_answer}. Give more weight in the last 2 seasons, where 49ers have same players and tendencies as the other NFC West teams.',\n",
        "    backstory=\"\"\"You are getting all data and analytics from NFL history.\n",
        "    You have focused your career in 49ers data.\n",
        "    You need to create forecasts for every game based on the last games.\"\"\",\n",
        "    verbose=verbose,\n",
        "    allow_delegation=True,\n",
        "    llm = llm,\n",
        "    tools=[search_tool]\n",
        "  )\n",
        "\n",
        "  critic = Agent(\n",
        "    role='Critic',\n",
        "    goal='Criticize output of research analysts to ensure the content is really insightful and not generic',\n",
        "    backstory=\"\"\"You are a senior NFL analyst, you have accurate of more than 75% of 49ers game forecasts since last 2 years\"\"\",\n",
        "    verbose=verbose,\n",
        "    allow_delegation=False,\n",
        "    llm = llm,\n",
        "    tools=[]\n",
        "  )\n",
        "\n",
        "  writer = Agent(\n",
        "    role='Responder',\n",
        "    goal=f'Understands user questions and can answer the main question: {question_to_answer}',\n",
        "    backstory=\"\"\"You understand users that need to know about 49ers games.\n",
        "    You want to understand them and give the best accurate answers from their questions.\"\"\",\n",
        "    verbose=verbose,\n",
        "    allow_delegation=False,\n",
        "    llm = llm,\n",
        "    tools=[]\n",
        "  )\n",
        "\n",
        "  # Create tasks for your agents\n",
        "  task1 = Task(\n",
        "    description=f\"\"\"Conduct a comprehensive research analysis to answer the question: {question_to_answer}\"\"\",\n",
        "    agent=researcher,\n",
        "    expected_output=f\"Conduct a comprehensive research analysis to answer the question: {question_to_answer}\"  # Add the expected output field\n",
        "  )\n",
        "\n",
        "  task2 = Task(\n",
        "    description=\"\"\"Critique the report and insights generated\"\"\",\n",
        "    agent=critic,\n",
        "    expected_output=\"A set of criticisms and suggested improvements\"  # Add the expected output field\n",
        "  )\n",
        "\n",
        "  task3 = Task(\n",
        "    description=f\"\"\"Using the insights provided, develop a research analysis to answer the question: {question_to_answer}\"\"\",\n",
        "    agent=writer,\n",
        "    expected_output=f\"A full research report of 1 paragraph research analysis answering the question: {question_to_answer}.\" # Added expected output\n",
        "  )\n",
        "\n",
        "  return {\n",
        "      'agents': [researcher, critic, writer],\n",
        "      'tasks': [task1, task2, task3]\n",
        "  }\n",
        "\n",
        "def getCrewWork(agents, tasks, verbose):\n",
        "  # Instantiate your crew with a sequential process\n",
        "  crew = Crew(\n",
        "    agents=agents,\n",
        "    tasks=tasks,\n",
        "    verbose=verbose, # You can set it to 1 or 2 to different logging levels,\n",
        "  )\n",
        "\n",
        "  # Get your crew to work!\n",
        "  result = crew.kickoff()\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "VNtYEn_bYzzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_to_answer = \"Does the 49ers the best team in NFC West?\"\n",
        "\n",
        "info = getAgentsTasks(question_to_answer, False)\n",
        "result = getCrewWork(info['agents'], info['tasks'], False)\n",
        "print(\"AGENTS => Does the 49ers the best team in NFC West?\")\n",
        "print(result)\n",
        "print(\"==========\")\n",
        "\n",
        "question_to_answer = \"Which is the team that the 49ers beat more in NFL?\"\n",
        "info = getAgentsTasks(question_to_answer, False)\n",
        "result = getCrewWork(info['agents'], info['tasks'], False)\n",
        "print(\"AGENTS => Which is the team that the 49ers beat more in NFL?\")\n",
        "print(result)\n",
        "print(\"==========\")\n",
        "\n",
        "question_to_answer = \"Which is the best NFL team based on the current data?\"\n",
        "info = getAgentsTasks(question_to_answer, False)\n",
        "result = getCrewWork(info['agents'], info['tasks'], False)\n",
        "print(\"AGENTS => Which is the best NFL team based on the current data?\")\n",
        "print(result)\n",
        "print(\"==========\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs_Bp_kG2PjD",
        "outputId": "8a622d66-6065-420a-b511-74b3b35a924e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n",
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGENTS => Does the 49ers the best team in NFC West?\n",
            "Based on the research conducted using the duckduckgo_search tool, it is evident that the San Francisco 49ers have been a dominant team in the NFC West over the past 2 seasons. However, a thorough analysis of the team's performance is necessary to determine if they are truly the best team in the division. While the report mentions that the 49ers have won the division title in 3 out of the last 5 seasons, it fails to provide specific details on the seasons in which they achieved this feat. Additionally, while their record has improved to 11-0 in the last 2 seasons, there is no comparison to their record in previous seasons, making it difficult to determine the extent of their improvement. Furthermore, the report mentions key players such as Brock Purdy and Christian McCaffrey as MVP candidates, but lacks analysis and statistics to support this claim. A more comprehensive analysis of the team's performance and comparison to other teams in the NFC West is necessary to determine if the 49ers are truly the best team in the division.\n",
            "==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGENTS => Which is the team that the 49ers beat more in NFL?\n",
            "After conducting thorough research and analysis, it can be concluded that the team that the 49ers have beaten the most in the NFL is the Green Bay Packers. However, there are some limitations and areas for improvement in the current report and insights. Firstly, the report lacks context as it does not provide details on the timeframe or notable events that may have contributed to the 49ers' success against the Packers. Additionally, the scope of the research is limited to only the last two seasons, which may not accurately reflect the overall history of the two teams. Furthermore, the data is incomplete as it only includes the 49ers' record against the Packers in the playoffs and regular season, without considering other games such as preseason or primetime matchups. Lastly, the report lacks comparison to other teams, which could provide a more comprehensive understanding of the 49ers' success against the Packers. In order to fully answer the question of which team the 49ers have beaten the most in the NFL, it is important to consider these criticisms and suggested improvements in future research and analysis.\n",
            "==========\n",
            "AGENTS => Which is the best NFL team based on the current data?\n",
            "Based on my research analysis, the best NFL team based on the current data is the San Francisco 49ers. While the report lacks comparison to other top teams in the league, such as the New England Patriots and the Pittsburgh Steelers, the 49ers have a strong record of Super Bowl championships and playoff wins. However, to provide a more comprehensive analysis, the report should include a comparison to other top teams and also consider data from the 49ers' entire history in the NFL. This will provide a more complete picture of the team's overall performance and solidify their position as one of the best teams in the league.\n",
            "==========\n"
          ]
        }
      ]
    }
  ]
}